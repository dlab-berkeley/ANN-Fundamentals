{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We discussed the basics of Artificial Neural Networks (ANNs) in the last two notebooks and implemented a simple version of an ANN ourselves. In practice, there are many packages that do this for us. In this notebook, we will build a Multiplayer Perceptron (MLP) classifier from the amazing [scikit-learn](http://scikit-learn.org/stable/) package. Feel free to check out their introduction and implementation of [ANNs](http://scikit-learn.org/stable/modules/neural_networks_supervised.html).   \n",
    "\n",
    "We will work on the famous [Handwritten Digits Data Sets](http://scikit-learn.org/stable/datasets/#optical-recognition-of-handwritten-digits-data-set) to classify the digits using a MLP. \n",
    "\n",
    "To motivate our work, consider when you deposit a check at the ATM or by taking a photo on your camera. An algorithm similar to what we will cover today is under working under the hood to transform your handwritten digits to digital data stored in your bank account!\n",
    "\n",
    "<img src=\"https://www.usglobalmail.com/wp-content/uploads/2016/12/check-deposits.png\" width=\"600\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import all the needed modules\n",
    "import itertools\n",
    "from sklearn.datasets import load_digits\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import numpy as np\n",
    "plt.style.use('seaborn-poster')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and visualize data \n",
    "\n",
    "Let's load the [Handwritten Digits Data Set](http://scikit-learn.org/stable/datasets/#optical-recognition-of-handwritten-digits-data-set) from sklearn. The data set contains images of handwritten digits with 10 classes where each class refers to a digit from 0 to 9. We can download this data from sklearn, so let's load the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "digits = load_digits()\n",
    "print('We have %d samples'%len(digits.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# let's look the classes we have\n",
    "print(np.unique(digits.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# let's look at one sample data, it is 64 features (8*8)\n",
    "digits.data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each datapoint is an array, respresenting an 8x8 grid of pixels and their values (darkness). \n",
    "\n",
    "We will plot the first 64 samples below to get a sense what we are working with with. Each image shows the handwritten digit and the correct digit class (target) on the left bottom corner.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "## plot the first 64 samples, and get a sense of the data\n",
    "fig = plt.figure(figsize = (8,8))\n",
    "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "for i in range(64):\n",
    "    ax = fig.add_subplot(8, 8, i+1, xticks=[], yticks=[])\n",
    "    ax.imshow(digits.images[i],cmap=plt.cm.binary,interpolation='nearest')\n",
    "    ax.text(0, 7, str(digits.target[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing the ANN classifier  \n",
    "\n",
    "We will split our dataset into two parts, 80% for training and 20% testing. The training data will be used to update the parameters (train) our model. The testing set will be used to see how well our model generalizes to to unseen data (test our model). \n",
    "\n",
    "We then will build an ANN model using the default parameter settings in sklearn, and train it using the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# split data to training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.2, random_state=16)\n",
    "print('Number of samples in training set: %d, number of samples in test set: %d'%(len(y_train), len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is [pre-processing](http://scikit-learn.org/stable/modules/preprocessing.html) the data. Pre-processing refers to the transformations we apply to our data **before** feeding it into our model. We will use the [StandardScaler in sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) to transform our data to have a mean of 0 and scaled to the standard deviation.\n",
    "\n",
    "Each datapoint is transformed as follows:\n",
    "\n",
    "$z = \\frac{x - u}{a}$\n",
    "\n",
    "Where:\n",
    "\n",
    "z = the transformed data point    \n",
    "x = the original data point     \n",
    "u = the mean of the entire dataset    \n",
    "a = the standard deviation of the dataset\n",
    "\n",
    "For those coming from statistics, this is the z-score of the datapoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "# Fit only to the training data\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Now apply the transformations to the data:\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block is to train the MLP classifier. See more details [here](http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Initialize ANN classifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(30,30,30), \n",
    "                    activation='logistic', \n",
    "                    max_iter = 1000,\n",
    "                    random_state=1)\n",
    "\n",
    "# Train the classifier with the traning data\n",
    "mlp.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will explain the options usually you need change or know briefly here:  \n",
    "* hidden_layer_sizes - a tuple to determine the number of neurons in each hidden layer (3 hidden layers with 30 neurons each in this example)\n",
    "* activation - defines the activation functions.   \n",
    "* alpha - a parameter to control the strength of [regularization][1] which helps avoid overfitting to the data by penalizing the size of the weights.  \n",
    "* solver - the algorithm for weight optimization. \n",
    "* batch_size - size of minibatches for stochastic optimizers. The minibatch is the number of datapoints when updating the weights.   \n",
    "* learning_rate - option to use different learning rate for weight updates. You can use constant learning rate, or changing the learning rate with progress.   \n",
    "* max_iter - maximum number of iterations. This will decide when to stop the solver, either the solver converges (determined by 'tol') or this maximum number of iterations.  \n",
    "* tol - tolerance for the optimization.  \n",
    "* momentum - momentum for gradient descent updates. This will try to avoid the local minimum trap.\n",
    "* random_state - determines random number generation for weights and bias initialization (for reproducibility).\n",
    "\n",
    "[1]: https://en.wikipedia.org/wiki/Regularization_(mathematics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test ANN classifier and evaluate  \n",
    "\n",
    "After we trained the ANN classifier, we will test the performance of the classifier using the test data. To evaluate the results, we will plot the [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(8, 8)) \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# predict results from the test data\n",
    "predicted = mlp.predict(X_test_scaled)\n",
    "\n",
    "# plot the confusion matrix\n",
    "cm = confusion_matrix(y_test,predicted)\n",
    "plot_confusion_matrix(cm, classes=digits.target_names,\n",
    "                      title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The x axis is the predicted digit from our MLP model, and the y axis is the true digit. The diagonal represents the correct results. As you can see we predict most images correctly!\n",
    "\n",
    "We can see the one of the most common errors is predicting a 4 when the true target is 7. A reasonable error I also make with my brain!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "Let's get the accuracy of our model, which is defined as the proportion of correct classification over the total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_accuracy(pred, target):\n",
    "    \"\"\"\n",
    "    Returns the accuracy of our model, the proportion of correct classifications relative to all datapoints.\n",
    "    \"\"\"\n",
    "    n = len(target)\n",
    "    # Compares our predicted and target arrays returning 1 if true and 0 if false\n",
    "    comparison = pred == target\n",
    "    # Sums the array giving us the number of correct predictions\n",
    "    correct = comparison.sum()\n",
    "    \n",
    "    # Returns the number of correct classifications proportional to the number of datapoints\n",
    "    return round(correct/n, 2)\n",
    "    \n",
    "print(\"Accuracy = \", model_accuracy(predicted, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad! Our model has an accuracy of 94% !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the test results  \n",
    "\n",
    "Let's visualize the first 64 digits in the test data. The green or the red digits at the left bottom corner are our estimation from the MLP model. Green text means we correctly classified the data, and while the red indicates the model gave the wrong prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "expected = y_test \n",
    "fig = plt.figure(figsize=(8, 8))  # figure size in inches\n",
    "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "# plot the digits: each image is 8x8 pixels\n",
    "for i in range(64):\n",
    "    ax = fig.add_subplot(8, 8, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(X_test.reshape(-1, 8, 8)[i], cmap=plt.cm.binary, interpolation='nearest')\n",
    "\n",
    "    # label the image with the target value\n",
    "    if predicted[i] == expected[i]:\n",
    "        ax.text(0, 7, str(predicted[i]), color='green')\n",
    "    else:\n",
    "        ax.text(0, 7, str(predicted[i]), color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, our model performed quite well with 94% accuracy on the test data! If we take a look at what the model got wrong, we may feel a bit bad. I can't help but feel some sympathy for our model, let's take a closer look at this image incorrectly classified as a 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_target_index = 38\n",
    "\n",
    "plt.imshow(X_test.reshape(-1, 8, 8)[wrong_target_index], cmap=plt.cm.binary, interpolation='nearest');\n",
    "plt.title(f\"An image of class {y_test[wrong_target_index]} incorrectly classified as class {predicted[wrong_target_index]}\", color=\"red\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At a quick glance (with my human eyes), it would be hard to tell if this was a 7 or 9. \n",
    "\n",
    "Remember, our predictions are only as good as the features in the data we put in!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newpackages-ann",
   "language": "python",
   "name": "newpackages-ann"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
