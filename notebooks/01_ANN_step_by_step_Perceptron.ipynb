{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We talked about the basics of Artificial Neural Networks (ANNs), gave an intuitive summary, and provided an example in the slides. In this notebook, we will continue to explore more of the ANN and implement a simple version of it.  \n",
    "\n",
    "After reading this notebook, you will understand some key concepts including the: *Inputs, Weights, Outputs, Targets, Activation Functions, Error, Bias term, Learning rate.*   \n",
    "\n",
    "Let's start with the simplest type of Artificial Neural Network, the [Perceptron](https://en.wikipedia.org/wiki/Perceptron). Developed back to the late 1950s, this was one of the first artificial neural networks to be produced. You can think of a perceptron as a two layer neural network without any hidden layers. Even though it has limitations, it contains the essential components found in ANNs.   \n",
    "\n",
    "Let's explore how a percepton works using a simple dataset with 5 observations where each sample has 3 features. The target is what we are ultimately trying to predict from the features. Our target is either 0 or 1 representing the different classes each sample can be, i.e. class 0, and class 1. Our goal is to build and train a simple Perceptron model that can **output the correct target** by feeding it our 3 **features as input**. See the following table. This example is modified from this [great post](http://iamtrask.github.io/2015/07/12/basic-python-network/). \n",
    "\n",
    "\n",
    "|Observation|Feature1|Feature2|Feature3|Target|\n",
    "|:------:|:------:|:------:|:------:|:----:|\n",
    "| 1 |    0   |    0   |    1   |   0  |\n",
    "| 2 |    1   |    1   |    1   |   1  |\n",
    "| 3 |    1   |    0   |    1   |   1  |\n",
    "| 4 |    0   |    1   |    1   |   0  |\n",
    "| 5 |    0   |    1   |    0   |   1  |\n",
    "\n",
    "Let's have a look at the structure of our model.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/qingkaikong/blog/master/39_ANN_part2_step_by_step/figures/figure1_perceptron_structure.jpg\" width=\"600\"/>  \n",
    "\n",
    "From the figure, we can see that we have two layers in this model: the input layer and the output layer. The input layer has 3 features that connect to the output layer via 3 weights. We  add an additional node with 1 as an input, and the weight associated with it is the $\\omega_0$, more on this later. The steps we will take to train this model are:\n",
    "1. Initialize the weights to small random numbers with both positive or negative values.\n",
    "2. For many iterations:  \n",
    "       Calculate the output value based on all data samples.\n",
    "       Update the weights based on the error.\n",
    "\n",
    "Before we implement this in code, we need go through some concepts:  \n",
    "\n",
    "### Bias term\n",
    "Now let's look at the extra 1 we added to the input layer. It is connected to the output layer by weight $\\omega_0$. Why do we add a 1 to the input? Consider the case when all our features are 0, and no matter what weights we have, we will always have 0 as output. Adding this 1 extra node can avoid this problem. The bias term fuctions just like a y-intercept in regression, allowing us to shift our function from being rooted at 0. \n",
    "\n",
    "### Activation functions   \n",
    "The output layer only has one node that sums all the passed input and determines whether the output should fire or not (this is ANN terminology related to the brain and the firing of neurons). Usually we use a 1 to indicate a neuron firing and a 0 to indicate a neuron not firing. In this case, we can see the sum of the weighted inputs are: z = $1*\\omega_0 + feature1*\\omega_1 + feature2*\\omega_2 + feature3*\\omega_3$. But what we want as the output is either 0 or 1 to represent two classes, or a number between 0 and 1, so that we can use it as a probability. Since this number z can be anything, how can we scale it to a value between 0 and 1, as a probability, or simply 0 and 1? Here, the [activation function](https://en.wikipedia.org/wiki/Activation_function) comes to the rescue! There are many different activation functions including:\n",
    "1. Logistic - Sigmoid\n",
    "2. Hyperbolic Tangent - Tanh\n",
    "3. Rectified Linear Unit - ReLU\n",
    "4. Leaky ReLU\n",
    "5. Softmax\n",
    "6. Many more!\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/2384/0*sIJ-gbjlz0zrz8lb.png\" width=\"600\"/>\n",
    "\n",
    "For demonstration purposes we will use the sigmoid (also called logistic) activation function. Using the sigmoid activation function has three major advantages:\n",
    "1. The output is scaled between 0 and 1.\n",
    "    - If the z value we is a large positive number, say 10, or a small negative number, say -10, the scaled value will be either 1 or 0. We can say at these cases, the network is very confident that the class is belong to certain class. \n",
    "    - If we have z relatively close to 0, for example, -1 to 1, then the scaled value will be around 0.2 to 0.7, which also indicates the network is not so confident about the result. \n",
    "2. The output is given as a probability.\n",
    "    - This gives us some metric for confidence about our result.\n",
    "3. We can take the derivative of the output.\n",
    "    -  Since the derivative can be used to update the weights while training our model, this property from the sigmoid function lets our shift the weights to predict the correct target.\n",
    "\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/qingkaikong/blog/master/39_ANN_part2_step_by_step/figures/figure2_sigmoid.jpg\" width=\"600\"/>   \n",
    "\n",
    "\n",
    "So now we have a perceptron network that can take some input of features, apply some weight to each feature, sum that up and pass it through an activation function to classify an observation into two different classes, great!\n",
    "\n",
    "But what if the result wrong? This is totally possible, since we initialized the weights as **random** small numbers. To fix our model, we need the perceptron to have the ability to learn from the data. \n",
    "\n",
    "### How to learn from error  \n",
    "\n",
    "Learning will be achieved by:\n",
    "1. Estimating how much error we make by using current weights, and then find some way to update the weights that we can reduce the error in the next time. I won't say too much here, but we will see more details with the explanation of the following code.  \n",
    "\n",
    "### Learning rate   \n",
    "\n",
    "Usually, we also need a learning rate to control how fast the network learns. We will see later in the code that the learning rate decide how much to change the weight by. We could miss it out, which would be the same as setting it to 1. But if we do that, the weights change a lot whenever there is a wrong answer, which tends to make the network unstable, so that it never settles down. The cost of having a small learning rate is that the weights need to see the inputs more often before they change significantly, so that the network takes longer to learn. However, it will be more stable and resistant to noise (errors) and inaccuracies in the data. \n",
    "\n",
    "Let's look at the code to do the above things to learn from data, and explain them line by line below:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output After Training:\n",
      "[[  1.46351277e-04]\n",
      " [  9.99906123e-01]\n",
      " [  9.99577840e-01]\n",
      " [  6.58013302e-04]\n",
      " [  9.99248929e-01]]\n",
      "Target\n",
      "[[0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# The activation function, we will use the sigmoid\n",
    "def sigmoid(x,deriv=False):\n",
    "    sig = 1/(1+np.exp(-x))\n",
    "    if(deriv==True):\n",
    "        return sig*(1-sig)\n",
    "    return sig\n",
    "\n",
    "# define learning rate\n",
    "learning_rate = 0.4\n",
    "\n",
    "# input dataset, note we add bias 1 to the input data\n",
    "X = np.array([[0,0,1],[1,1,1],[1,0,1],[0,1,1],[0,1,0]])\n",
    "X = np.concatenate((np.ones((len(X), 1)), X), axis = 1)\n",
    "\n",
    "# output dataset           \n",
    "y = np.array([[0,1,1,0,1]]).T\n",
    "\n",
    "# seed random numbers to make calculation\n",
    "# deterministic (just a good practice)\n",
    "np.random.seed(1)\n",
    "\n",
    "# initialize weights randomly with mean 0\n",
    "weights_0 = 2*np.random.random((4,1)) - 1\n",
    "\n",
    "# train the network with 50000 iterations\n",
    "for iter in range(50000):\n",
    "\n",
    "    # forward propagation\n",
    "    layer_0 = X\n",
    "    layer_1_output = sigmoid(np.dot(layer_0,weights_0))\n",
    "\n",
    "    # how much difference? This will be the error of \n",
    "    # our estimation and the true value\n",
    "    layer1_error = y - layer_1_output\n",
    "\n",
    "    # multiply how much we missed by the\n",
    "    # slope of the sigmoid at the values at output layer\n",
    "    # we also multiply the input to take care of the negative case\n",
    "    layer1_delta = learning_rate * layer1_error * sigmoid(layer_1_output,True)\n",
    "    layer1_delta = np.dot(layer_0.T,layer1_delta)\n",
    "\n",
    "    # update weights by simply adding the delta\n",
    "    weights_0 += layer1_delta\n",
    "    \n",
    "print(\"Output After Training:\")\n",
    "print(layer_1_output)\n",
    "print('Target')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain line by line  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Line 1:** This line imports the numpy module, which is a linear algebra library.   \n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "```\n",
    "\n",
    "**Line 3:** This block defines the activation function, which is a function to convert any number to a probability between 0 and 1 as we discussed above.   \n",
    "\n",
    "```python\n",
    "# The activation function, we will use the sigmoid\n",
    "def sigmoid(x,deriv=False):\n",
    "    sig = 1/(1+np.exp(-x))\n",
    "    if(deriv==True):\n",
    "        return sig*(1-sig)\n",
    "    return sig\n",
    "```\n",
    "\n",
    "**Line 10:** Here we define our learning rate, this will control how fast the network learns from the data. Usually this learning rate will be a number within 0 - 1, with 0 means the network will not learn at all, and 1 means the network will learn a full speed. \n",
    "\n",
    "```python\n",
    "# define learning rate\n",
    "learning_rate = 0.4\n",
    "```\n",
    "\n",
    "**Line 13:** This initializes the input dataset as numpy matrix. Each row is a single data sample, and each column corresponds to one features (one of the input nodes). And we also add the bias term 1 in line 14. You can see that we now have 4 input nodes and 5 training examples.   \n",
    "\n",
    "```python\n",
    "# input dataset, note we add bias 1 to the input data\n",
    "X = np.array([[0,0,1],[1,1,1],[1,0,1],[0,1,1],[1,0,0]])\n",
    "X = np.concatenate((np.ones((len(X), 1)), X), axis = 1)\n",
    "```\n",
    "\n",
    "**Line 17:** This initializes our output dataset. \".T\" is the transpose function, which to convert our output data to a column vector. You can see that we have 5 rows and 1 column, corresponds to 5 data samples and 1 output node.  \n",
    "\n",
    "```python\n",
    "# output dataset           \n",
    "y = np.array([[0,1,1,0,1]]).T\n",
    "```\n",
    "\n",
    "**Line 21:** Before we generate the random weights, we use a seed to make sure that every time we have the same set of random number generated. This is very useful when we test the algorithm, and compare the results with others. This means that your results and my results should be the same. But in reality when you use the algorithm, you don't need to seed it.   \n",
    "\n",
    "```python\n",
    "# seed random numbers to make calculation\n",
    "# deterministic (just a good practice)\n",
    "np.random.seed(1)\n",
    "```\n",
    "\n",
    "**Line 24:** This initializes our weights to connect the input layer to the output layer. Since we have 4 input nodes (including the bias term), we initialize the random weights as dimension (4,1). Also note that the random numbers we initialized are within -1 to 1, with a mean of 0. There is quite a bit of theory that goes into weight initialization. For now, just take it as a best practice that it's a good idea to have a mean of zero in weight initialization. \n",
    "\n",
    "```python\n",
    "# initialize weights randomly with mean 0\n",
    "weights_0 = 2*np.random.random((4,1)) - 1\n",
    "```\n",
    "\n",
    "**Line 27:** We begin the training and make the Perceptron to learn in 50000 iterations. In each of the iteration, the algorithm will learn from the error it made.  \n",
    "\n",
    "```python\n",
    "# train the network with 50000 iterations\n",
    "for iter in xrange(50000):\n",
    "```\n",
    "\n",
    "**Line 30:** We just explicitly assign out input data to layer_0 (since we have 2 layers, we will call it layer_0, and layer_1). We're going to process all the data at the same time in this implementation, this is called 'batch processing'. There's another type of learning called ['online learning'](https://en.wikipedia.org/wiki/Online_machine_learning), which essentially change the weights whenever there's new data sample available, but we won't talk it here.   \n",
    "\n",
    "```python\n",
    "    # forward propagation\n",
    "    layer_0 = X\n",
    "```\n",
    "\n",
    "**Line 31:** This is the forward propagation. It has two steps, first, the input data from the input layer and propagate to the output layer via the weights, and second, the activation function convert it into a number between 0 and 1. The first step is achieved by the np.dot function, np.dot(layer_0,weights_0) = $1*\\omega_0 + feature1*\\omega_1 + feature2*\\omega_2 + feature3*\\omega_3$, we can call the derived number is z. The second step is passing this number z to the sigmoid function to get a number between 0 to 1.   \n",
    "\n",
    "```python\n",
    "    layer_1_output = sigmoid(np.dot(layer_0,weights_0))\n",
    "```\n",
    "\n",
    "**Line 35:** This is the error we made using the current weight, it is simply the true answer (y) minus our estimation (layer_1_output). The error of each of the data sample we input into the network is stored here as a 5 by 1 matrix.  \n",
    "\n",
    "```python\n",
    "    # how much difference? This will be the error of \n",
    "    # our estimation and the true value\n",
    "    layer1_error = y - layer_1_output\n",
    "```\n",
    "\n",
    "**Line 40:** This is the most important part - learning. This is the line that makes our algorithm learn from the data. It calculates how much we will change each of the weights in the current iteration. It has 3 parts that multiplied together, (1) the learning rate, (2) the error we just got, and (3) the derivative of the sigmoid function at the output value. \n",
    "\n",
    "```python\n",
    "    # multiply how much we missed by the\n",
    "    # slope of the sigmoid at the values at output layer\n",
    "    # we also multiply the input to take care of the negative case\n",
    "    layer1_delta = learning_rate * layer1_error * sigmoid(layer_1_output,True)\n",
    "```\n",
    "\n",
    "The first term is the learning rate, which controls how fast we will learn, it is just a constant in this case, say, we can choose it as 0.4. The larger the values is, the faster the network will learn, but may make the learning unstable and cause the results oscillating that never get the correct results.      \n",
    "\n",
    "The second term is the error we made. Let's think this error a little more: we have two class, class 0 and class 1. Therefore, we can have two type of error, true class is 0, but our estimation is larger than 0, the other case is true class is 1, but our estimation is less than 1. The error will be a negative number for the first case, but a positive number for the second. If we assume all the input node is positive, and we get an error as negative number, then we want to reduce the weight to make next estimation smaller. Same thing for the other case, if we have the error as a positive number, then we will want to increase the weights, so that in the next iteration, our estimation will be larger. This is the purpose we include the error term here to determine how we change the weights. But wait, what if the input nodes contain negative input? This will switch the values over, and reverse the direction we want to change the weights. How can we avoid this case? Well, it is quite simple, we can just multiply the input into this function, the negative error with negative input multiply will be a positive number, which satisfy our need. This is where line 42 comes in, we separate these two lines for more clear explanation.    \n",
    "\n",
    "The final term is the derivative of the sigmoid function evaluated at the output value. We can see a simple plot of the sigmoid function and it's derivatives at different places. The derivative at x is the slope of the sigmoid curve at value x. We can clearly see the slope is different at various value x, ranging from 0 (when x value is approaching to two end, i.e. either really large or really small, you can also see the slope is very flat) to 1 (when x value is close to the 0, the slope is very steep). This means we will multiply another value that is between 0 to 1 to the error we made that already scaled with the learning rate. If we look carefully with the figure, the slope of the green and purple dots are flat than the blue dot, which means they will have a smaller value. The green and purple dots represent more confidence of the result to be one class, for example, the green dot the sigmoid value is about 0.9, which is much close to the class 1. But the blue dot has a sigmoid value 0.5, which we have no idea whether it should belong to class 1 or class 0. Therefore, this slope is large when we have no confidence of determine the class of result, and small when we have more confidence of the class of the results. Now, this makes sense, if the current weights already made a very good estimate of the class (for the green dot), we will want to update the weights really small or even not update it. But if the current estimation is not clear, for example, the blue case, we will want to change the weights relatively large to make it clearer. Therefore, combining the 3 terms, we can get a delta value for each of the weight we want to change in the direction to reduce the error.    \n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/qingkaikong/blog/master/39_ANN_part2_step_by_step/figures/figure3_sigmoid_derivative.jpg\" width=\"600\"/> \n",
    "\n",
    "**Line 41:** As we talked about the negative input case (see line 39 second term explanation), where we need multiply the input to keep the sign correctly (to keep the direction we want to change the weights correctly!).   \n",
    "\n",
    "```python\n",
    "    layer1_delta = np.dot(layer_0.T,layer1_delta)\n",
    "```\n",
    "\n",
    "**Line 44:** This is the last line, it aims to update the current weights by simply adding the delta we just determined to the current weights.  \n",
    "\n",
    "```python\n",
    "    # update weights by simply adding the delta\n",
    "    weights_0 += layer1_delta\n",
    "```\n",
    "\n",
    "**Line 47:** This line just print out the final results we get after the network learned 50000 iterations, and we can see we get a pretty decent results.   \n",
    "\n",
    "```python\n",
    "print(layer_1_output)\n",
    "```\n",
    "\n",
    "This concludes this part by showing you all the important part of the ANN (perceptron) algorithm. But the perceptron has its own limation, which actually caused the ANN winter we talked about in the 1970s until researchers found the way to solve it - the multilayer perceptron algorithm, which we will talk in the next part. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References  \n",
    "\n",
    "[A Neural Network in 11 lines of Python](http://iamtrask.github.io/2015/07/12/basic-python-network/) (I thank the author, since my example is modified from his blog).    \n",
    "[Machine learning - An Algorithmic Perspective](https://seat.massey.ac.nz/personal/s.r.marsland/MLBook.html)   \n",
    "[Single-Layer Neural Networks and Gradient Descent](http://sebastianraschka.com/Articles/2015_singlelayer_neurons.html)\n",
    "[Activation functions and when to use what](https://medium.com/@himanshuxd/activation-functions-sigmoid-relu-leaky-relu-and-softmax-basics-for-neural-networks-and-deep-8d9c70eed91e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
